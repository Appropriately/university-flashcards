\card{
  What does $O(<expr>)$ mean?
}{
  The complexity (i.e. running time/space) is bounded by the $<expr>$.
}

\card{
  What does $\Theta(<expr>)$ mean?
}{
  The complexity (i.e. space/running time) has the complexity proportional to
  $<expr>$.
}

\card{
  What does $\Omega(<expr>)$ mean?
}{
  The complexity (i.e. running time/space) is \textit{at least} by the $<expr>$.
}

\card{
  Say that the input represents a positive integer, $x$, what is the size of $n$?
 }{
  $\left \lfloor \log_b x \right \rfloor + 1$
  Where $b$ is the number representation, usually binary (so 2).
 }

\card{
  What does it mean by $O(1)$?
}{
  It takes a constant time, no matter the amount of data, to perform the operation.
}

% Divide-and-conquer %
\card{MergeSort and QuickSort of examples of what algorithmic technique?}{\textbf{Divide-and-conquer}}

\card{What are the three steps of \textbf{Divide-and-conquer}?}{
  \begin{flushleft}
    - We divide the input into parts. \\ 
    - Solve the parts (often recusrively). \\
    - Combine the solutions to give the final result.
  \end{flushleft}
  Three steps of Divide-and-conquer
}

% Greedy %
\card{What is the \textbf{Greedy} algorithm? Give an example in term of the knapsack problem.}{
  A greedy algorithm is an algorithmic paradigm that follows the problem solving heuristic of making the locally optimal choice at each stage with the hope of finding a global optimum.\\
  With the knapscak problem, organise all possible items by their value to weight ratio. Then iterate through this list, adding them to the knapsack where possible.
}

% Dynamic Programming %
\flashcard{
  Dynamic Programming is a \blank{bottom-up} method - we solve all \blank{smaller problems} first and then \blank{combine them} to solve the given problem.
}

\card{Give some examples of optimisation problems with \textbf{dynamic programming}.}{
  \begin{flushleft}
    * Some path-finding algorithms use dynamic programming, e.g. Floyd's algorithm.\\
    * Some text similarity tests, e.g. longest common subsequence.\\
    * Knapsack problems: The O/1 knapsack can be solved using dynamic programming.\\
    * Constructiong optimal search trees.\\
    * Some travelling sales person problems.\\
    * Genome matching and protein-chain matching.
  \end{flushleft}
  Optimisation problems with dynamic problems.
}

\card{Define \textbf{tractable} and \textbf{intractable problems}.}{
  Tractable: An algorithm that can be solved in \textbf{polynomial} time.\\
  Intractable: A problem that can be solved in theory (e.g. given large but finite resources, especially time), but for which in practice any solution takes too many resources to be useful.
}
