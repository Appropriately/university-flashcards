\card{Explain each stage of a 5 stage pipeline}
{
  IF - Fetch instruction from memory\\
  ID - Decode instruction; select registers\\
  EX - Perform an operation or calculate an address\\
  MEM - Access an operand in memory\\
  WB - Write to registers
}

\card{Briefly explain what pipelining is}
{
  Where we get all the components of the CPU working at the same time, with
  buffers that are flushed every clock cycle inbetween each stage, so that we
  can overlap the execution of instructions to increase overall clock speed.
}

\card{What is a control hazard?}
{
  If we have a branch at the ID stage, then the fetched instruction at the
  IF stage will have to be ignored all the way down the pipeline, wasting one
  full cycle and causing a \textit{bubble}.
}

\card{What are two ways of dealing with control hazards?}
{
  Pipeline bubbling (abort instructions that are incorrect) and branch
  prediction (guess what way to branch).
}

\card{Briefly explain what branch prediction is}
{
  If we can remember what address a branch directed us to fetch next from what
  it did when we executed that branch previously, then we can pre-emptively
  load that instruction in the IF stage instead of fetching the instruction at
  the PC.
}

\card{What is used to implement branch prediction and what does it do?}
{
  A branch target buffer which maps the virtual address of one branch instruction onto the virtual address of the instruction that is branched to
}

\card{What is a data hazard?}
{
  A data dependency between instructions. This is where we execute instructions that depend on each other in parallel or close together and the correct data might not be in the right place (e.g. registers).
}

\card{How can we mitigate Data Hazardsâ€™ effects?}
{
  Extra lines in the data path (Forwarding). \\
  Adding NOPs. Reordering instructions.
}

\card{What is forwarding?}
{
  Where we add extra paths to the architecture to pass updated register values back to previous stages of the pipeline to avoid data hazards.
}

\card{How can we exploit instruction level parallelism?}
{
  Fetch multiple instructions per cycle\\
  Have multiple ALU's to execute instructions in parallel (superscalar)\\ 
  Have common registers and caches, since the instructions are operating on the same data
}

\card{What does VLIW stand for?}
{
  Very Long Instruction Word
}

\card{How can we implement an out of order processor?}
{
  Have a buffer that instructions are fetched into\\
  A scheduler to choose which instructions to execute at what times\\
  A cache to store memory and register accesses until all instructions have
  finished so that the application can execute normally as though instructions
  were executed in parallel
}

\flashcard{
  For pipelines with multiple execution flows, each flow is known as a \flashcard{Functional Unit}.
}

\flashcard{
  \blank{Cache misses}: long wait before finishing execution.
}

\flashcard{
  \blank{Structural Hazard}: the required resource (i.e., Functional Unit) is not available.
}

\card{
  What is scoreboarding?
}{
  Scoreboarding is a method for dynamically scheduling a pipeline so that the instructions can execute out of order when there are no conflicts and the hardware is available. \\
  In a scoreboard, the data dependencies of every instruction are logged. Instructions are released only when the scoreboard determines that there are no conflicts with previously issued and incomplete instructions. 
}


\flashcard{
  \blank{True dependency} (read-after-write): Instruction A depends on the output of a previous instruction B.
}

\flashcard{
  \blank{Anti-dependency} (write-after-read): Instruction A writes in the input of a previous instruction B. We need to ensure B reads the correct value instead of that generated by A.
}

\flashcard{
  \blank{Output Dependency} (write-after-write): Instruction A and B write in the same register. We need to ensure that the register keeps the value of the later instruction.
}

\flashcard{ 
  \begin{flushleft}
    \blank{Issue}: Decode instructions, check for structural hazards. Checks for WAW. \\ 
    \blank{Read operands}: Wait until no data hazards, then read operands. Checks for RAW \\ 
    \blank{Execution}: Operate on operands. \\ 
    \blank{Write Result}: Finish execution and write results. Checks for WAR. \\ 
  \end{flushleft}
  The four stages of the Scoreboard pipeline
}

\flashcard{
  \blank{Reservation stations}: implicit register renaming by buffering source operands.
}

\card{In the context of Tomasulo, what is register renaming?}
{
  The concept of renaming a register to eliminate WAR \& WAW hazards. \\
  Can be done by a compiler, but Tomasulo does it transparently in hardware (by the \textbf{Reservation Stations}).
}

\card{What's a \textbf{Common Data Bus} and how does it differ to a normal one?}
{
  64 bits of data + 4 bits of Functional Unit address. \\
  Functional units broadcast their result. \\ 
  Reservation stations take the operand if it matches any input Functional Unit. \\
  Register bank takes the operand if it matches the Functional Unit writing the result.
}

\flashcard{
  The first stage of the Tomasulo algorithm is \blank{Issue}. \\ It gets the instruction from the FP Op Queue. \\
  If the reservation station is free (i.e. no \blank{structural hazard}), issue instruction and read operands. \\
  Otherwise, \blank{stall the pipeline}.
}

\flashcard{
  The second stage of the Tomasulo algorithm is \blank{Execute}. \\
  When both source operands are ready then execute; if not ready, watch \blank{Common Data bus} for results.
}

\flashcard{
  The third (and final) stage of the Tomasulo algorithm is \blank{Write back}. \\
  Write on Common Data Bus to all \blank{awaiting units}; free \blank{reservation station}.
}

\card{What are the benefits of Out of Order Processors?}
{
  Accelerates the execution of programs. \\
  More efficient design by increasing the utilisation of processor resources.
}

\card{What are the limitations of Out of Order Processors?}
{
  More complex design. \\ 
  Expensive in terms of area & power. \\
  Non precise interrupts.
}